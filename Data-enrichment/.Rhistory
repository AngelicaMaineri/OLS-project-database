ungroup() |>
print()
(list = unique(df3$keywords))
View(df)
View(df2)
View(df3)
install.packages("word2vec")
library(word2vec)
## 5. Embeddings
set.seed(42)
model <-word2vec(x =listdf3,type ="cbow",dim =15,iter =20)
(listdf3 = unique(df3$keywords))
model <-word2vec(x =listdf3,type ="cbow",dim =15,iter =20)
embedding <-as.matrix(model)
embedding <-predict(model,c("humanities","social sciences"),type ="embedding")
embedding
model <-word2vec(x =listdf3,type ="cbow",iter =20)
embedding <-as.matrix(model)
embedding <-predict(model,c("humanities","social sciences"),type ="embedding")
embedding
embedding <-as.matrix(model)
embedding <-predict(model,c("xylogenesi","village"),type ="embedding")
embedding
lookslike <-predict(model,c("humanities"),type ="nearest",top_n =5)lookslike
model <-word2vec(x =listdf3,type ="cbow",iter =20)
lookslike <-predict(model,c("humanities"),type ="nearest",top_n =5)
listdf3
lookslike <-predict(model,c("social science"),type ="nearest",top_n =5)
lookslike <-predict(model,c("science"),type ="nearest",top_n =5)
lookslike
View(model)
lookslike <-predict(model,c("video"),type ="nearest",top_n =5)
lookslike
lookslike <-predict(model,c("turing way"),type ="nearest",top_n =5)
lookslike <-predict(model,c("data"),type ="nearest",top_n =5)
lookslike
model <-word2vec(x =df$description,type ="cbow",iter =20)
lookslike <-predict(model,c("data"),type ="nearest",top_n =5)
lookslike
lookslike <-predict(model,c("social"),type ="nearest",top_n =5)
lookslike
lookslike <-predict(model,c("social sciences"),type ="nearest",top_n =5)
lookslike <-predict(model,c("social science"),type ="nearest",top_n =5)
lookslike <-predict(model,c("sociology"),type ="nearest",top_n =5)
lookslike <-predict(model,c("humanities"),type ="nearest",top_n =5)
model <-word2vec(x =df$description,type ="cbow",iter =20)
model
df$description
lookslike <-predict(model,c("Bioinformatics"),type ="nearest",top_n =5)
lookslike
domains = read_delim("Data/domains.csv")
domains
## 5. String match
unique(listdf3)%in%unique(domains$discipline)
# remove capitalisation
domains = domains |>
mutate(domain=tolower(domain),
discipline=tolower(discipline))
## 5. String match
unique(listdf3)%in%unique(domains$discipline)
df_enriched = left_join(df2, domains, by=c("keyword", "discipline"))
df_enriched
df_enriched = left_join(df2, domains, by=c("keywords", "discipline"))
## 5. String match
unique(df2$keywords)%in%unique(domains$discipline)
df_enriched = left_join(df2, domains, by=c("keywords", "discipline"))
df2
## 3. Prepare data ----
# rename name field to title
df = df |>
rename(title = name)
# add identifier for projects - OLS + cohort + number
df = df |>
group_by(cohort) |>
mutate(row = row_number()) |>
ungroup()
df = df |>
mutate(id = paste("OLS", df$cohort, df$row, sep = "-")) |>
print()
df$id
#make list of keywords, retain project ID
df2 = df |>
mutate(keywords = strsplit(keywords, ",[ ]")) |>
unnest(keywords) |>
#  group_by(id) |>
#  mutate(row = row_number()) |>
# spread(row, keywords) |>
print()
df2 = df2 |>
dplyr::select(c("keywords", "id")) |>
mutate(keywords = tolower(keywords)) |> # remove capitalization to avoid duplication
print(n=100)
# make list of unique keywords, remove duplicates
(list = unique(df2$keywords))
# with occurrences
df3 = df2 |>
mutate(n=1) |>
dplyr::select("keywords", "n") |>
group_by(keywords) |>
count(n) |>
ungroup() |>
print()
# remove capitalisation
domains = domains |>
mutate(domain=tolower(domain),
discipline=tolower(discipline))
(listdf3 = unique(df3$keywords))
## 5. String match
unique(df2$keywords)%in%unique(domains$discipline)
df_enriched = left_join(df2, domains, by=c("keywords", "discipline"))
df2
domains$discipline
df2$keywords
## 5. String match
(unique(df2$keywords)%in%unique(domains$discipline))
df_enriched = left_join(df2, domains, key=c("keywords", "discipline"))
df_enriched = left_join(df2, domains, by=c("keywords" = "discipline"))
df_enriched
count(df_enriched, domain)
df2$keywords
write.csv(df2, file = "data/keywords")
write.csv(df2, file = "data/keywords.csv")
domains = read_delim("Data/domains.csv")
## 5. String match
(unique(df2$keywords)%in%unique(domains$discipline))
df_enriched = left_join(df2, domains, by=c("keywords" = "discipline"))
count(df_enriched, domain)
df_enriched
df_dom = left_join(df, df_enriched, by="id") |>
print(n=100)
df_dom = left_join(df, df_enriched, by="id", multiple = "all") |>
print(n=100)
View(df_dom)
df_dom = left_join(df, df_enriched, by="id") |>
print(n=100)
? left_join
df_dom = left_join(df, df_enriched, by="id", multiple = "any") |>
print(n=100)
df_dom = left_join(df, df_enriched, by="id", multiple = "first") |>
print(n=100)
df_dom = left_join(df, df_enriched, by="id", multiple = "first") |>
print(n=100) |>
count(domain)
count(df_dom, domain)
df_dom = left_join(df, df_enriched, by="id", multiple = "last") |>
print(n=100)
count(df_dom, domain)
df_dom = left_join(df, df_enriched, by="id", multiple = "any") |>
print(n=100)
count(df_dom, domain)
count(df_enriched, domain)
View(df_dom)
View(df_dom)
View(df_enriched)
df_dom = left_join(df, df_enriched, by="id", multiple = "any") |>
print(n=100)
df_dom = left_join(df, df_enriched, by="id", multiple = "any") |>
print(n=100) |>
col_order <- c("id")
colnames(df_dom)
df_dom = left_join(df, df_enriched, by="id", multiple = "any") |>
dplyr::select(!keywords.y) |>
print(n=100)
colnames(df_dom)
df_dom = left_join(df, df_enriched, by="id", multiple = "any") |>
dplyr::select(!keywords.y) |>
rename(keywords.x = keywords) |>
print(n=100)
df_dom = left_join(df, df_enriched, by="id", multiple = "any") |>
dplyr::select(!keywords.y, row) |>
rename(keywords.x = keywords) |>
print(n=100)
df_dom = left_join(df, df_enriched, by="id", multiple = "any") |>
dplyr::select(!keywords.y, !row) |>
rename(keywords.x = keywords) |>
print(n=100)
df_dom = left_join(df, df_enriched, by="id", multiple = "any") |>
dplyr::select(!keywords.y, !row) |>
rename(keywords = keywords.x) |>
print(n=100)
col_order <- c("id", "title","participants","mentors","description","cohort", "keywords", "status", "domain")
df_dom = df_dom[, col_order]
df_dom
write.csv(df_dom, file="projects_domain.csv")
#' OLS-Project-databases
#' Assign domain
#'
#' Created on 28/04/2023 by Angelica Maineri
#'
#' Aim: write script to automatically tag the domain (SSH, LSH, NES, Other)
#' based on keywords
## 1. Load and install packages -----
# Uncomment (= remove the #) the following lines as fit:
#install.packages("tidyverse")
library(tidyverse) # for most operations
# for wordclouds
install.packages("wordcloud")
library(wordcloud)
install.packages("RColorBrewer")
library(RColorBrewer)
install.packages("wordcloud2")
library(wordcloud2)
# for embeddings
install.packages("word2vec")
library(word2vec)
## 2. Load data ----
df = read_delim("Data/projects.csv")
domains = read_delim("Data/domains.csv")
# Create list domain
# Science = Astronomy, Chemistry, Computer Science, Earth Sciences, Life Sciences, Mathematics and Physics.
# SSH =
## 3. Prepare data ----
# rename name field to title
df = df |>
rename(title = name)
# add identifier for projects - OLS + cohort + number
df = df |>
group_by(cohort) |>
mutate(row = row_number()) |>
ungroup()
df = df |>
mutate(id = paste("OLS", df$cohort, df$row, sep = "-")) |>
print()
df$id
#make list of keywords, retain project ID
df2 = df |>
mutate(keywords = strsplit(keywords, ",[ ]")) |>
unnest(keywords) |>
#  group_by(id) |>
#  mutate(row = row_number()) |>
# spread(row, keywords) |>
print()
df2 = df2 |>
dplyr::select(c("keywords", "id")) |>
mutate(keywords = tolower(keywords)) |> # remove capitalization to avoid duplication
print(n=100)
# make list of unique keywords, remove duplicates
(list = unique(df2$keywords))
# with occurrences
df3 = df2 |>
mutate(n=1) |>
dplyr::select("keywords", "n") |>
group_by(keywords) |>
count(n) |>
ungroup() |>
print()
# remove capitalisation
domains = domains |>
mutate(domain=tolower(domain),
discipline=tolower(discipline))
(listdf3 = unique(df3$keywords))
## 4. Wordcloud -----
set.seed(42) # for reproducibility
(wc1 = wordcloud(words = df3$keywords, freq = df3$nn, min.freq = 1, max.freq = 50, colors=brewer.pal(8, "Dark2")))
## 5. String match
(unique(df2$keywords)%in%unique(domains$discipline))
write.csv(df2, file = "data/keywords.csv")
df_enriched = left_join(df2, domains, by=c("keywords" = "discipline"))
count(df_enriched, domain)
df_dom = left_join(df, df_enriched, by="id", multiple = "any") |>
dplyr::select(!keywords.y, !row) |>
rename(keywords = keywords.x) |>
print(n=100)
col_order <- c("id", "title","participants","mentors","description","cohort", "keywords", "status", "domain")
df_dom = df_dom[, col_order]
# export
write.csv(df_dom, file="projects_domain.csv")
## Next steps
#' Improve domains classification
#' Add "open science" or similar; add 'community building"
install.packages("RColorBrewer")
# export
write.csv(df_dom, file="Data/projects_domain.csv")
df_dom = df_dom[, col_order]
#' OLS-Project-databases
#' Assign domain
#'
#' Created on 28/04/2023 by Angelica Maineri
#'
#' Aim: write script to automatically tag the domain (SSH, LSH, NES, Other)
#' based on keywords
## 1. Load and install packages -----
# Uncomment (= remove the #) the following lines as fit:
#install.packages("tidyverse")
library(tidyverse) # for most operations
# for wordclouds
install.packages("wordcloud")
library(wordcloud)
install.packages("RColorBrewer")
library(RColorBrewer)
install.packages("wordcloud2")
library(wordcloud2)
# for embeddings
install.packages("word2vec")
library(word2vec)
## 2. Load data ----
df = read_delim("Data/projects.csv")
domains = read_delim("Data/domains.csv")
# Create list domain
# Science = Astronomy, Chemistry, Computer Science, Earth Sciences, Life Sciences, Mathematics and Physics.
# SSH =
## 3. Prepare data ----
# rename name field to title
df = df |>
rename(title = name)
# add identifier for projects - OLS + cohort + number
df = df |>
group_by(cohort) |>
mutate(row = row_number()) |>
ungroup()
df = df |>
mutate(id = paste("OLS", df$cohort, df$row, sep = "-")) |>
print()
df$id
#make list of keywords, retain project ID
df2 = df |>
mutate(keywords = strsplit(keywords, ",[ ]")) |>
unnest(keywords) |>
#  group_by(id) |>
#  mutate(row = row_number()) |>
# spread(row, keywords) |>
print()
df2 = df2 |>
dplyr::select(c("keywords", "id")) |>
mutate(keywords = tolower(keywords)) |> # remove capitalization to avoid duplication
print(n=100)
# make list of unique keywords, remove duplicates
(list = unique(df2$keywords))
# with occurrences
df3 = df2 |>
mutate(n=1) |>
dplyr::select("keywords", "n") |>
group_by(keywords) |>
count(n) |>
ungroup() |>
print()
# remove capitalisation
domains = domains |>
mutate(domain=tolower(domain),
discipline=tolower(discipline))
(listdf3 = unique(df3$keywords))
## 4. Wordcloud -----
set.seed(42) # for reproducibility
(wc1 = wordcloud(words = df3$keywords, freq = df3$nn, min.freq = 1, max.freq = 50, colors=brewer.pal(8, "Dark2")))
## 5. String match
(unique(df2$keywords)%in%unique(domains$discipline))
write.csv(df2, file = "data/keywords.csv")
df_enriched = left_join(df2, domains, by=c("keywords" = "discipline"))
count(df_enriched, domain)
df_dom = left_join(df, df_enriched, by="id", multiple = "any") |>
dplyr::select(!keywords.y, !row) |>
rename(keywords = keywords.x) |>
print(n=100)
col_order <- c("id", "title","participants","mentors","description","cohort", "keywords", "status", "domain")
df_dom = df_dom[, col_order]
install.packages("RColorBrewer")
df_dom
write.csv()
? write.csv
# export
write.csv(df_dom, file="Data/projects_domain.csv", fileEncoding = "UTF-8")
# remove capitalisation
domains = domains |>
mutate(discipline=tolower(discipline))
df_enriched = left_join(df2, domains, by=c("keywords" = "discipline"))
count(df_enriched, domain)
df_dom = left_join(df, df_enriched, by="id", multiple = "any") |>
dplyr::select(!keywords.y, !row) |>
rename(keywords = keywords.x) |>
print(n=100)
col_order <- c("id", "title","participants","mentors","description","cohort", "keywords", "status", "domain")
df_dom = df_dom[, col_order]
df_dom
# export
write.csv(df_dom, file="Data/projects_domain.csv", fileEncoding = "UTF-8")
library(RColorBrewer)
#' OLS-Project-databases
#' Assign domain
#'
#' Created on 28/04/2023 by Angelica Maineri
#'
#' Aim: write script to automatically tag the domain (SSH, LSH, NES, Other)
#' based on keywords
## 1. Load and install packages -----
# Uncomment (= remove the #) the following lines as fit:
#install.packages("tidyverse")
library(tidyverse) # for most operations
# for wordclouds
#install.packages("wordcloud")
library(wordcloud)
#install.packages("RColorBrewer")
library(RColorBrewer)
#install.packages("wordcloud2")
library(wordcloud2)
# for embeddings
#install.packages("word2vec")
library(word2vec)
## 2. Load data ----
df = read_delim("Data/projects.csv")
domains = read_delim("Data/domains.csv")
# Create list domain
# Science = Astronomy, Chemistry, Computer Science, Earth Sciences, Life Sciences, Mathematics and Physics.
# SSH =
## 3. Prepare data ----
# rename name field to title
df = df |>
rename(title = name)
# add identifier for projects - OLS + cohort + number
df = df |>
group_by(cohort) |>
mutate(row = row_number()) |>
ungroup()
df = df |>
mutate(id = paste("OLS", df$cohort, df$row, sep = "-")) |>
print()
df$id
#make list of keywords, retain project ID
df2 = df |>
mutate(keywords = strsplit(keywords, ",[ ]")) |>
unnest(keywords) |>
#  group_by(id) |>
#  mutate(row = row_number()) |>
# spread(row, keywords) |>
print()
df2 = df2 |>
dplyr::select(c("keywords", "id")) |>
mutate(keywords = tolower(keywords)) |> # remove capitalization to avoid duplication
print(n=100)
# make list of unique keywords, remove duplicates
(list = unique(df2$keywords))
# with occurrences
df3 = df2 |>
mutate(n=1) |>
dplyr::select("keywords", "n") |>
group_by(keywords) |>
count(n) |>
ungroup() |>
print()
# remove capitalisation
domains = domains |>
mutate(discipline=tolower(discipline))
(listdf3 = unique(df3$keywords))
## 4. Wordcloud -----
set.seed(42) # for reproducibility
(wc1 = wordcloud(words = df3$keywords, freq = df3$nn, min.freq = 1, max.freq = 50, colors=brewer.pal(8, "Dark2")))
## 5. String match
(unique(df2$keywords)%in%unique(domains$discipline))
write.csv(df2, file = "data/keywords.csv")
df_enriched = left_join(df2, domains, by=c("keywords" = "discipline"))
count(df_enriched, domain)
df_dom = left_join(df, df_enriched, by="id", multiple = "any") |>
dplyr::select(!keywords.y, !row) |>
rename(keywords = keywords.x) |>
print(n=100)
col_order <- c("id", "title","participants","mentors","description","cohort", "keywords", "status", "domain")
df_dom = df_dom[, col_order]
df_dom
# export
write.csv(df_dom, file="Data/projects_domain.csv", fileEncoding = "UTF-8")
## Next steps
#' Improve domains classification
#' Add "open science" or similar; add 'community building"
df_dom
df2 = df2 |>
dplyr::select(c("keywords", "id")) |>
mutate(keywords = tolower(keywords)) |> # remove capitalization to avoid duplication
mutate(keywords = str_trim(keywords, "right")) |>  #remove all trailing whitespace
mutate(keywords = str_trim(keywords, "left")) |> #remove all leading whitespace
print(n=100)
#make list of keywords, retain project ID
df2 = df |>
mutate(keywords = strsplit(keywords, ",[ ]")) |>
unnest(keywords) |>
#  group_by(id) |>
#  mutate(row = row_number()) |>
# spread(row, keywords) |>
print()
df2 = df2 |>
dplyr::select(c("keywords", "id")) |>
mutate(keywords = tolower(keywords)) |> # remove capitalization to avoid duplication
mutate(keywords = str_trim(keywords, "right")) |>  #remove all trailing whitespace
mutate(keywords = str_trim(keywords, "left")) |> #remove all leading whitespace
print(n=100)
# make list of unique keywords, remove duplicates
(list = unique(df2$keywords))
# with occurrences
df3 = df2 |>
mutate(n=1) |>
dplyr::select("keywords", "n") |>
group_by(keywords) |>
count(n) |>
ungroup() |>
print()
# remove capitalisation
domains = domains |>
mutate(discipline=tolower(discipline))
(listdf3 = unique(df3$keywords))
## 4. Wordcloud -----
set.seed(42) # for reproducibility
## 5. String match
(unique(df2$keywords)%in%unique(domains$discipline))
df_enriched = left_join(df2, domains, by=c("keywords" = "discipline"))
count(df_enriched, domain)
df_dom = left_join(df, df_enriched, by="id", multiple = "any") |>
dplyr::select(!keywords.y, !row) |>
rename(keywords = keywords.x) |>
print(n=100)
col_order <- c("id", "title","participants","mentors","description","cohort", "keywords", "status", "domain")
df_dom = df_dom[, col_order]
df_dom
# export
write.csv(df_dom, file="Data/projects_domain.csv", fileEncoding = "UTF-8")
